feat: ✅ Establish Stable Kernel Safety Point — DeepSeek LLM Adapter Fully Integrated

This commit officially stabilizes full end-to-end orchestration for Extraction + System Prompt Synthesis across all personas.

✅ Changes finalized in this checkpoint:
- ExtractionOrchestrator: ✅ stable JSON schema extraction pipeline (principles, methods, frameworks, theories, notes)
- CognitiveKernel: ✅ robust multi-agent output verification with ambiguity reinforcement
- Unified LLMAdapterRouter: ✅ provider-agnostic routing now fully supports DeepSeek & OpenAI backends
- DeepSeekAdapter: ✅ callChatModel correctly handling messages array formatting with proper role casting ('system' | 'user')
- SystemPromptGenerator: ✅ fully generates prompts for persona-based downstream usage
- Frontend Upload Pipeline: ✅ DOCX, PDF, TXT, and Image OCR flows operational
- Full safeDecodeBuffer support for non-binary uploads
- End-to-end file parsing + cognitive extraction + system prompt response validated against multiple documents

⚠️ Known Minor Gaps (Non-Blocking)
- Frontend: Add better loading states for "Generate Prompt" button
- GenerationConfig: Currently defaulting to {}, schema extension optional in next phase

🧪 Test Suite Status:
- ✅ Manual file parsing tests (PDF, DOCX, TXT)
- ✅ Persona pathway tests (Educator, Researcher, Creator)
- ✅ DeepSeek multi-agent LLM payload verification

📦 Kernel Stability Tag: v1.0-SAFEPOINT-DEEPSEEK-STABLE
